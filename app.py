import streamlit as st
import pandas as pd
import numpy as np
import pickle
import json
from sklearn.ensemble import GradientBoostingClassifier, IsolationForest
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, silhouette_score, davies_bouldin_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.datasets import load_iris, load_wine, load_breast_cancer
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime

def convert_numpy_types(obj):
    """Convierte tipos numpy a tipos nativos de Python para serializaci√≥n JSON"""
    if isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    elif isinstance(obj, np.ndarray):
        return convert_numpy_types(obj.tolist())
    elif isinstance(obj, (np.integer, np.int32, np.int64)):
        return int(obj)
    elif isinstance(obj, (np.floating, np.float32, np.float64)):
        return float(obj)
    elif isinstance(obj, np.bool_):
        return bool(obj)
    else:
        return obj

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Aplicaci√≥n de Machine Learning",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# T√≠tulo principal
st.title("ü§ñ Aplicaci√≥n de Modelos de Machine Learning")
st.markdown("---")

# Sidebar para navegaci√≥n
st.sidebar.title("üîß Panel de Control")
mode = st.sidebar.radio(
    "Selecciona el modo:",
    ["üè† Inicio", "üìä Modo Supervisado", "üîç Modo No Supervisado", "üìÅ Zona de Exportaci√≥n"]
)

# Funci√≥n para cargar datasets
@st.cache_data
def load_dataset(dataset_name):
    """Carga diferentes datasets seg√∫n la selecci√≥n"""
    
    # Diccionarios de traducci√≥n para caracter√≠sticas
    iris_features_es = {
        'sepal length (cm)': 'Longitud S√©palo (cm)',
        'sepal width (cm)': 'Anchura S√©palo (cm)',
        'petal length (cm)': 'Longitud P√©talo (cm)',
        'petal width (cm)': 'Anchura P√©talo (cm)'
    }
    
    wine_features_es = {
        'alcohol': 'Alcohol',
        'malic_acid': '√Åcido M√°lico',
        'ash': 'Cenizas',
        'alcalinity_of_ash': 'Alcalinidad de las Cenizas',
        'magnesium': 'Magnesio',
        'total_phenols': 'Fenoles Totales',
        'flavanoids': 'Flavonoides',
        'nonflavanoid_phenols': 'Fenoles No Flavonoides',
        'proanthocyanins': 'Proantocianinas',
        'color_intensity': 'Intensidad del Color',
        'hue': 'Tono',
        'od280/od315_of_diluted_wines': 'OD280/OD315 de Vinos Diluidos',
        'proline': 'Prolina'
    }
    
    breast_cancer_features_es = {
        'mean radius': 'Radio Promedio',
        'mean texture': 'Textura Promedio',
        'mean perimeter': 'Per√≠metro Promedio',
        'mean area': '√Årea Promedio',
        'mean smoothness': 'Suavidad Promedio',
        'mean compactness': 'Compacidad Promedio',
        'mean concavity': 'Concavidad Promedio',
        'mean concave points': 'Puntos C√≥ncavos Promedio',
        'mean symmetry': 'Simetr√≠a Promedio',
        'mean fractal dimension': 'Dimensi√≥n Fractal Promedio',
        'radius error': 'Error del Radio',
        'texture error': 'Error de Textura',
        'perimeter error': 'Error del Per√≠metro',
        'area error': 'Error del √Årea',
        'smoothness error': 'Error de Suavidad',
        'compactness error': 'Error de Compacidad',
        'concavity error': 'Error de Concavidad',
        'concave points error': 'Error de Puntos C√≥ncavos',
        'symmetry error': 'Error de Simetr√≠a',
        'fractal dimension error': 'Error de Dimensi√≥n Fractal',
        'worst radius': 'Radio Peor',
        'worst texture': 'Textura Peor',
        'worst perimeter': 'Per√≠metro Peor',
        'worst area': '√Årea Peor',
        'worst smoothness': 'Suavidad Peor',
        'worst compactness': 'Compacidad Peor',
        'worst concavity': 'Concavidad Peor',
        'worst concave points': 'Puntos C√≥ncavos Peor',
        'worst symmetry': 'Simetr√≠a Peor',
        'worst fractal dimension': 'Dimensi√≥n Fractal Peor'
    }
    
    if dataset_name == "Flores Iris":
        data = load_iris()
        feature_names_es = [iris_features_es.get(name, name) for name in data.feature_names]
        df = pd.DataFrame(data.data, columns=feature_names_es)
        df['target'] = data.target
        target_names_es = ['Setosa', 'Versicolor', 'Virginica']
        df['target_names'] = df['target'].map({i: name for i, name in enumerate(target_names_es)})
        return df, feature_names_es, target_names_es
    
    elif dataset_name == "Vinos":
        data = load_wine()
        feature_names_es = [wine_features_es.get(name, name) for name in data.feature_names]
        df = pd.DataFrame(data.data, columns=feature_names_es)
        df['target'] = data.target
        target_names_es = ['Clase 0', 'Clase 1', 'Clase 2']
        df['target_names'] = df['target'].map({i: name for i, name in enumerate(target_names_es)})
        return df, feature_names_es, target_names_es
    
    elif dataset_name == "C√°ncer de Mama":
        data = load_breast_cancer()
        feature_names_es = [breast_cancer_features_es.get(name, name) for name in data.feature_names]
        df = pd.DataFrame(data.data, columns=feature_names_es)
        df['target'] = data.target
        target_names_es = ['Maligno', 'Benigno']
        df['target_names'] = df['target'].map({i: name for i, name in enumerate(target_names_es)})
        return df, feature_names_es, target_names_es

# Variables de sesi√≥n para mantener estado
if 'supervised_model' not in st.session_state:
    st.session_state.supervised_model = None
if 'unsupervised_model' not in st.session_state:
    st.session_state.unsupervised_model = None
if 'dataset' not in st.session_state:
    st.session_state.dataset = None
if 'dataset_name' not in st.session_state:
    st.session_state.dataset_name = None
if 'supervised_metrics' not in st.session_state:
    st.session_state.supervised_metrics = {}
if 'unsupervised_metrics' not in st.session_state:
    st.session_state.unsupervised_metrics = {}

# P√ÅGINA DE INICIO
if mode == "üè† Inicio":
    st.markdown("## üìã Descripci√≥n de la Aplicaci√≥n")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### üéØ Modelos Implementados
        
        **Modelo Supervisado:**
        - **Gradient Boosting Classifier**
        - Algoritmo de ensemble que combina m√∫ltiples √°rboles de decisi√≥n
        - Excelente para clasificaci√≥n con alta precisi√≥n
        
        **Modelo No Supervisado:**
        - **Isolation Forest**
        - Algoritmo para detecci√≥n de anomal√≠as
        - Identifica puntos at√≠picos en los datos
        """)
    
    with col2:
        st.markdown("""
        ### üìä Datasets Disponibles
        
        - **Flores Iris**: Clasificaci√≥n de especies de flores (4 caracter√≠sticas)
        - **Vinos**: Clasificaci√≥n de tipos de vino (13 caracter√≠sticas)
        - **C√°ncer de Mama**: Diagn√≥stico m√©dico (30 caracter√≠sticas)
        
        ### üìÅ Funcionalidades
        
        - Entrenamiento interactivo de modelos
        - Evaluaci√≥n con m√©tricas est√°ndar
        - Visualizaciones interactivas
        - Exportaci√≥n a JSON y PKL
        """)
    
    # Informaci√≥n detallada de los datasets
    st.markdown("---")
    st.markdown("### üìã Informaci√≥n Detallada de los Datasets")
    
    dataset_tab1, dataset_tab2, dataset_tab3 = st.tabs(["üå∏ Flores Iris", "üç∑ Vinos", "üè• C√°ncer de Mama"])
    
    with dataset_tab1:
        col_a, col_b = st.columns(2)
        with col_a:
            st.markdown("""
            **üìä Caracter√≠sticas del Dataset:**
            - **Muestras:** 150 flores
            - **Caracter√≠sticas:** 4 medidas f√≠sicas
            - **Clases:** 3 especies de iris
            - **Balanceado:** S√≠ (50 ejemplos por clase)
            
            **üå∏ Especies:**
            - Setosa
            - Versicolor  
            - Virginica
            """)
        with col_b:
            st.markdown("""
            **üìè Caracter√≠sticas Medidas:**
            - Longitud del S√©palo (cm)
            - Anchura del S√©palo (cm)
            - Longitud del P√©talo (cm)
            - Anchura del P√©talo (cm)
            
            **üéØ Ideal Para:**
            - Aprendizaje de clasificaci√≥n
            - Visualizaci√≥n de datos
            - Comparaci√≥n de algoritmos
            """)
    
    with dataset_tab2:
        col_a, col_b = st.columns(2)
        with col_a:
            st.markdown("""
            **üìä Caracter√≠sticas del Dataset:**
            - **Muestras:** 178 vinos
            - **Caracter√≠sticas:** 13 an√°lisis qu√≠micos
            - **Clases:** 3 tipos de vino
            - **Origen:** Regi√≥n de Italia
            
            **üç∑ Tipos:**
            - Clase 0, Clase 1, Clase 2
            - Diferentes cultivares
            """)
        with col_b:
            st.markdown("""
            **üß™ An√°lisis Qu√≠micos:**
            - Alcohol, √Åcido M√°lico, Cenizas
            - Alcalinidad, Magnesio, Fenoles
            - Flavonoides, Proantocianinas
            - Intensidad del Color, Tono
            - Y m√°s componentes qu√≠micos
            
            **üéØ Ideal Para:**
            - Clasificaci√≥n multiclase
            - An√°lisis de componentes
            """)
    
    with dataset_tab3:
        col_a, col_b = st.columns(2)
        with col_a:
            st.markdown("""
            **üìä Caracter√≠sticas del Dataset:**
            - **Muestras:** 569 diagn√≥sticos
            - **Caracter√≠sticas:** 30 medidas morfol√≥gicas
            - **Clases:** 2 (Maligno/Benigno)
            - **Aplicaci√≥n:** Diagn√≥stico m√©dico
            
            **üè• Diagn√≥sticos:**
            - Maligno (c√°ncer)
            - Benigno (no c√°ncer)
            """)
        with col_b:
            st.markdown("""
            **üî¨ Medidas Morfol√≥gicas:**
            - Radio, Textura, Per√≠metro
            - √Årea, Suavidad, Compacidad
            - Concavidad, Puntos C√≥ncavos
            - Simetr√≠a, Dimensi√≥n Fractal
            - Para media, error y peor caso
            
            **üéØ Ideal Para:**
            - Diagn√≥stico binario
            - Detecci√≥n de anomal√≠as
            - Aplicaciones m√©dicas
            """)
    
    st.markdown("---")
    st.markdown("### üöÄ ¬°Comienza seleccionando un modo en el panel lateral!")

# MODO SUPERVISADO
elif mode == "üìä Modo Supervisado":
    st.markdown("## üìä Modelo Supervisado - Gradient Boosting")
    
    # Descripci√≥n del modelo
    st.markdown("### üéØ ¬øQu√© es Gradient Boosting?")
    
    with st.expander("üìö Descripci√≥n del Algoritmo", expanded=False):
        st.markdown("""
        **Gradient Boosting** es un algoritmo de aprendizaje autom√°tico de tipo ensemble que:
        
        **Funcionamiento:**
        - Combina m√∫ltiples √°rboles de decisi√≥n d√©biles
        - Cada √°rbol nuevo corrige los errores del anterior
        - Utiliza gradiente descendente para minimizar la funci√≥n de p√©rdida
        - Construye el modelo de forma secuencial
        
        **Ventajas:**
        - Alta precisi√≥n en clasificaci√≥n
        - Maneja bien datos mixtos (num√©ricos y categ√≥ricos)
        - Robusto ante outliers
        - No requiere normalizaci√≥n de datos
        
        **Aplicaciones:**
        - Clasificaci√≥n de im√°genes
        - Diagn√≥stico m√©dico
        - Detecci√≥n de fraudes
        - Sistemas de recomendaci√≥n
        """)
    
    # Configuraci√≥n del modelo con explicaciones
    st.sidebar.markdown("### ‚öôÔ∏è Configuraci√≥n del Modelo")
    
    # Selecci√≥n de dataset
    st.sidebar.markdown("### üìä Selecci√≥n de Dataset")
    dataset_name = st.sidebar.radio(
        "Elige un dataset:",
        ["Flores Iris", "Vinos", "C√°ncer de Mama"]
    )
    
    # Cargar dataset
    if st.sidebar.button("üîÑ Cargar Dataset"):
        # Limpiar modelos anteriores al cambiar dataset
        if st.session_state.dataset_name != dataset_name:
            st.session_state.supervised_model = None
            st.session_state.supervised_metrics = {}
        
        st.session_state.dataset = load_dataset(dataset_name)
        st.session_state.dataset_name = dataset_name
        st.success(f"Dataset {dataset_name} cargado exitosamente!")
    
    if st.session_state.dataset is not None:
        df, feature_names, target_names = st.session_state.dataset
        
        # Mostrar informaci√≥n del dataset
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("üìè Filas", df.shape[0])
        with col2:
            st.metric("üìä Columnas", df.shape[1] - 2)  # -2 por target y target_names
        with col3:
            st.metric("üéØ Clases", len(target_names))
        
        # Mostrar preview del dataset
        st.markdown("### üëÄ Vista previa del dataset")
        
        # Control para n√∫mero de filas a mostrar
        col1, col2 = st.columns([3, 1])
        with col2:
            num_rows = st.selectbox(
                "Filas a mostrar:",
                [5, 10, 20, 50, "Todas"],
                index=1,  # Default: 10 filas
                key="preview_rows"
            )
        
        # Mostrar dataset seg√∫n selecci√≥n
        if num_rows == "Todas":
            st.dataframe(df, use_container_width=True)
            st.info(f"üìä Mostrando todas las {len(df)} filas del dataset")
        else:
            st.dataframe(df.head(num_rows), use_container_width=True)
            st.info(f"üìä Mostrando las primeras {num_rows} filas de {len(df)} totales")
        
        # Preparar datos
        X = df[feature_names]
        y = df['target']
        
        # Configuraci√≥n del modelo
        st.sidebar.markdown("### ‚öôÔ∏è Configuraci√≥n del Modelo")
        n_estimators = st.sidebar.slider("N√∫mero de estimadores", 50, 500, 100)
        max_depth = st.sidebar.slider("Profundidad m√°xima", 3, 10, 6)
        learning_rate = st.sidebar.slider("Tasa de aprendizaje", 0.01, 0.3, 0.1, 0.01)
        
        with st.sidebar.expander("üìä Par√°metros Explicados"):
            st.markdown("""
            **N√∫mero de Estimadores:**
            - Cantidad de √°rboles en el ensemble
            - M√°s √°rboles = mayor precisi√≥n pero m√°s lento
            - Rango recomendado: 100-300
            
            **Profundidad M√°xima:**
            - Qu√© tan profundo puede crecer cada √°rbol
            - Mayor profundidad = m√°s complejo
            - Evita overfitting con valores bajos
            
            **Tasa de Aprendizaje:**
            - Qu√© tanto contribuye cada √°rbol
            - Valores bajos = aprendizaje m√°s conservador
            - Balance entre velocidad y estabilidad
            """)
        
        # Entrenar modelo
        if st.sidebar.button("üöÄ Entrenar Modelo"):
            with st.spinner("Entrenando modelo..."):
                # Divisi√≥n de datos
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42, stratify=y
                )
                
                # Crear y entrenar modelo
                model = GradientBoostingClassifier(
                    n_estimators=n_estimators,
                    max_depth=max_depth,
                    learning_rate=learning_rate,
                    random_state=42
                )
                model.fit(X_train, y_train)
                
                # Predicciones
                y_pred = model.predict(X_test)
                
                # Calcular m√©tricas
                metricas = {
                    'exactitud': accuracy_score(y_test, y_pred),
                    'precision': precision_score(y_test, y_pred, average='weighted'),
                    'sensibilidad': recall_score(y_test, y_pred, average='weighted'),
                    'puntuacion_f1': f1_score(y_test, y_pred, average='weighted')
                }
                
                # Guardar en sesi√≥n (incluyendo los datos de entrenamiento)
                st.session_state.supervised_model = model
                st.session_state.supervised_metrics = metricas
                st.session_state.X_test = X_test
                st.session_state.y_test = y_test
                st.session_state.y_pred = y_pred
                st.session_state.current_X = X  # Guardar las caracter√≠sticas actuales
                st.session_state.current_feature_names = feature_names  # Guardar nombres de caracter√≠sticas
                st.session_state.current_target_names = target_names  # Guardar nombres de clases
                
                st.success("¬°Modelo entrenado exitosamente!")
        
        # Mostrar m√©tricas si el modelo est√° entrenado
        if st.session_state.supervised_model is not None:
            # Verificar si el dataset actual coincide con el modelo entrenado
            if (hasattr(st.session_state, 'current_feature_names') and 
                hasattr(st.session_state, 'dataset_name') and 
                st.session_state.dataset_name == dataset_name):
                
                st.markdown("### üìà M√©tricas del Modelo")
                
                with st.expander("üìä ¬øQu√© significan estas m√©tricas?", expanded=False):
                    st.markdown("""
                    **Exactitud (Accuracy):**
                    - Porcentaje de predicciones correctas sobre el total
                    - Ideal: cerca de 1.0 (100%)
                    - √ötil cuando las clases est√°n balanceadas
                    
                    **Precisi√≥n (Precision):**
                    - De las predicciones positivas, cu√°ntas fueron correctas
                    - Evita falsos positivos
                    - Importante en diagn√≥sticos m√©dicos
                    
                    **Sensibilidad (Recall):**
                    - De los casos reales positivos, cu√°ntos detect√≥
                    - Evita falsos negativos
                    - Cr√≠tico en detecci√≥n de enfermedades
                    
                    **Puntuaci√≥n F1:**
                    - Media arm√≥nica entre precisi√≥n y sensibilidad
                    - Balance entre ambas m√©tricas
                    - √∫til cuando hay desbalance de clases
                    """)
                
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("üéØ Exactitud", f"{st.session_state.supervised_metrics['exactitud']:.3f}")
                with col2:
                    st.metric("üîç Precisi√≥n", f"{st.session_state.supervised_metrics['precision']:.3f}")
                with col3:
                    st.metric("üìä Sensibilidad", f"{st.session_state.supervised_metrics['sensibilidad']:.3f}")
                with col4:
                    st.metric("‚öñÔ∏è Puntuaci√≥n F1", f"{st.session_state.supervised_metrics['puntuacion_f1']:.3f}")
                
                # Matriz de confusi√≥n
                from sklearn.metrics import confusion_matrix
                cm = confusion_matrix(st.session_state.y_test, st.session_state.y_pred)
                
                # Usar los nombres de clases del modelo entrenado
                target_labels = (st.session_state.current_target_names 
                               if hasattr(st.session_state, 'current_target_names') 
                               else target_names)
                
                fig, ax = plt.subplots(figsize=(8, 6))
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                           xticklabels=target_labels, yticklabels=target_labels)
                ax.set_title('Matriz de Confusi√≥n')
                ax.set_xlabel('Predicci√≥n')
                ax.set_ylabel('Valor Real')
                st.pyplot(fig)
                
            else:
                st.warning("‚ö†Ô∏è Has cambiado de dataset. Por favor, entrena nuevamente el modelo para ver m√©tricas y hacer predicciones.")
            
            # Prueba interactiva
            st.markdown("### üéÆ Prueba Interactiva")
            st.markdown("Ajusta los valores para hacer una predicci√≥n:")
            
            # Verificar que tenemos los datos del modelo entrenado
            if (hasattr(st.session_state, 'current_feature_names') and 
                hasattr(st.session_state, 'current_X') and 
                hasattr(st.session_state, 'current_target_names')):
                
                current_features = st.session_state.current_feature_names
                current_X = st.session_state.current_X
                current_targets = st.session_state.current_target_names
                
                # Crear sliders para cada feature del modelo entrenado
                input_values = []
                
                # Organizar en columnas para mejor visualizaci√≥n
                n_features = len(current_features)
                n_cols = min(3, n_features)  # M√°ximo 3 columnas
                cols = st.columns(n_cols)
                
                for i, feature in enumerate(current_features):
                    with cols[i % n_cols]:
                        min_val = float(current_X[feature].min())
                        max_val = float(current_X[feature].max())
                        mean_val = float(current_X[feature].mean())
                        
                        value = st.slider(
                            f"{feature[:20]}...", 
                            min_val, max_val, mean_val,
                            key=f"slider_{i}_{st.session_state.dataset_name}"
                        )
                        input_values.append(value)
                
                # Hacer predicci√≥n
                if st.button("üîÆ Predecir"):
                    prediction = st.session_state.supervised_model.predict([input_values])
                    prediction_proba = st.session_state.supervised_model.predict_proba([input_values])
                    
                    predicted_class = prediction[0]
                    predicted_label = current_targets[predicted_class]
                    confidence = np.max(prediction_proba) * 100
                    
                    st.success(f"**Predicci√≥n:** {predicted_label}")
                    st.info(f"**Confianza:** {confidence:.1f}%")
                    
                    # Guardar √∫ltima predicci√≥n
                    st.session_state.last_prediction = {
                        'input': input_values,
                        'output_class': int(predicted_class),
                        'output_label': predicted_label,
                        'confidence': float(confidence)
                    }
            else:
                st.warning("‚ö†Ô∏è Por favor, entrena primero el modelo para habilitar las predicciones.")

# MODO NO SUPERVISADO
elif mode == "üîç Modo No Supervisado":
    st.markdown("## üîç Modelo No Supervisado - Isolation Forest")
    
    # Descripci√≥n del modelo
    st.markdown("### üïµÔ∏è ¬øQu√© es Isolation Forest?")
    
    with st.expander("üìö Descripci√≥n del Algoritmo", expanded=False):
        st.markdown("""
        **Isolation Forest** es un algoritmo de detecci√≥n de anomal√≠as que:
        
        **Funcionamiento:**
        - Construye √°rboles de aislamiento aleatorios
        - Separa puntos mediante divisiones aleatorias
        - Las anomal√≠as se a√≠slan m√°s r√°pidamente
        - No requiere etiquetas (aprendizaje no supervisado)
        
        **Principio:**
        - Puntos normales necesitan m√°s divisiones para aislarse
        - Anomal√≠as se separan con pocas divisiones
        - Calcula un "score de anomal√≠a" para cada punto
        
        **Aplicaciones:**
        - Detecci√≥n de fraudes financieros
        - Monitorizaci√≥n de sistemas
        - Control de calidad industrial
        - Seguridad en redes
        """)
    
    st.markdown("**Nota:** Selecciona un dataset para analizar anomal√≠as.")
    
    # Selecci√≥n de dataset independiente para modo no supervisado
    st.sidebar.markdown("### üìä Selecci√≥n de Dataset")
    dataset_name_unsupervised = st.sidebar.radio(
        "Elige un dataset para an√°lisis de anomal√≠as:",
        ["Flores Iris", "Vinos", "C√°ncer de Mama"],
        key="unsupervised_dataset"
    )
    
    # Cargar dataset seleccionado
    df_unsupervised, feature_names_unsupervised, target_names_unsupervised = load_dataset(dataset_name_unsupervised)
    
    # Mostrar informaci√≥n del dataset seleccionado
    st.info(f"üìä Dataset seleccionado: **{dataset_name_unsupervised}**")
    
    # Mostrar informaci√≥n del dataset
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("üìè Filas", df_unsupervised.shape[0])
    with col2:
        st.metric("üìä Columnas", df_unsupervised.shape[1] - 2)  # -2 por target y target_names
    with col3:
        st.metric("üéØ Clases", len(target_names_unsupervised))
    
    # Preparar datos (solo caracter√≠sticas, sin etiquetas)
    X_unsupervised = df_unsupervised[feature_names_unsupervised]
    
    # Normalizar datos
    scaler = StandardScaler()
    X_scaled_unsupervised = scaler.fit_transform(X_unsupervised)
    
    # Configuraci√≥n del modelo
    st.sidebar.markdown("### ‚öôÔ∏è Configuraci√≥n Isolation Forest")
    
    contamination = st.sidebar.slider(
        "Contaminaci√≥n (% de anomal√≠as)", 
        0.01, 0.5, 0.1, 0.01
    )
    n_estimators = st.sidebar.slider("N√∫mero de √°rboles", 50, 200, 100)
    
    with st.sidebar.expander("üîç Par√°metros Explicados"):
        st.markdown("""
        **Contaminaci√≥n:**
        - Porcentaje esperado de anomal√≠as
        - 0.1 = 10% de datos son at√≠picos
        - Ajustar seg√∫n conocimiento del dominio
        
        **N√∫mero de √Årboles:**
        - Cantidad de √°rboles de aislamiento
        - M√°s √°rboles = estimaci√≥n m√°s estable
        - Valor t√≠pico: 100-200
        
        **C√≥mo Interpretar:**
        - Score negativo = m√°s probable anomal√≠a
        - Score positivo = comportamiento normal
        - Umbral autom√°tico basado en contaminaci√≥n
        """)
    
    # Entrenar modelo
    if st.sidebar.button("üöÄ Entrenar Isolation Forest"):
        with st.spinner("Entrenando modelo de detecci√≥n de anomal√≠as..."):
            # Crear y entrenar modelo
            iso_forest = IsolationForest(
                contamination=contamination,
                n_estimators=n_estimators,
                random_state=42
            )
            
            # Entrenar y predecir
            anomaly_labels = iso_forest.fit_predict(X_scaled_unsupervised)
            anomaly_scores = iso_forest.decision_function(X_scaled_unsupervised)
            
            # Convertir etiquetas (-1 = anomal√≠a, 1 = normal)
            cluster_labels = np.where(anomaly_labels == -1, 1, 0)  # 1 = anomal√≠a, 0 = normal
            
            # Calcular m√©tricas
            try:
                silhouette = silhouette_score(X_scaled_unsupervised, cluster_labels)
                davies_bouldin = davies_bouldin_score(X_scaled_unsupervised, cluster_labels)
            except:
                silhouette = np.nan
                davies_bouldin = np.nan
            
            metricas = {
                'puntuacion_silueta': silhouette,
                'davies_bouldin': davies_bouldin,
                'anomalias_detectadas': np.sum(anomaly_labels == -1),
                'puntos_normales': np.sum(anomaly_labels == 1)
            }
            
            # Guardar en sesi√≥n
            st.session_state.unsupervised_model = iso_forest
            st.session_state.unsupervised_metrics = metricas
            st.session_state.anomaly_labels = anomaly_labels
            st.session_state.cluster_labels = cluster_labels
            st.session_state.anomaly_scores = anomaly_scores
            st.session_state.X_scaled_unsupervised = X_scaled_unsupervised
            st.session_state.scaler_unsupervised = scaler
            st.session_state.unsupervised_dataset_name = dataset_name_unsupervised
            st.session_state.unsupervised_df = df_unsupervised
            st.session_state.unsupervised_feature_names = feature_names_unsupervised
            
            st.success("¬°Modelo de detecci√≥n de anomal√≠as entrenado!")
    
    # Mostrar resultados si el modelo est√° entrenado (FUERA del bot√≥n)
    if st.session_state.unsupervised_model is not None:
        # Verificar que el dataset actual coincide con el modelo entrenado
        if (hasattr(st.session_state, 'unsupervised_dataset_name') and 
            st.session_state.unsupervised_dataset_name == dataset_name_unsupervised):
                
            
            st.markdown("### üìä Resultados de Detecci√≥n de Anomal√≠as")
            
            with st.expander("üïµÔ∏è ¬øC√≥mo interpretar los resultados?", expanded=False):
                st.markdown("""
                **Puntuaci√≥n Silueta:**
                - Mide qu√© tan bien separados est√°n los clusters
                - Rango: -1 a 1
                - Valores altos (>0.5) = buena separaci√≥n
                - Cerca de 0 = clusters superpuestos
                
                **√çndice Davies-Bouldin:**
                - Mide la compacidad dentro de clusters
                - Valores m√°s bajos = mejor clustering
                - Ideal: cercano a 0
                - Compara distancias intra vs inter-cluster
                
                **Anomal√≠as vs Normales:**
                - N√∫mero de puntos clasificados como at√≠picos
                - Basado en el par√°metro de contaminaci√≥n
                - Revisar si el ratio es razonable para tu dominio
                """)
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                if not np.isnan(st.session_state.unsupervised_metrics['puntuacion_silueta']):
                    st.metric("üìè Puntuaci√≥n Silueta", 
                            f"{st.session_state.unsupervised_metrics['puntuacion_silueta']:.3f}")
                else:
                    st.metric("üìè Puntuaci√≥n Silueta", "N/A")
            
            with col2:
                if not np.isnan(st.session_state.unsupervised_metrics['davies_bouldin']):
                    st.metric("üìä √çndice Davies-Bouldin", 
                            f"{st.session_state.unsupervised_metrics['davies_bouldin']:.3f}")
                else:
                    st.metric("üìä √çndice Davies-Bouldin", "N/A")
            
            with col3:
                st.metric("‚ö†Ô∏è Anomal√≠as", 
                        st.session_state.unsupervised_metrics['anomalias_detectadas'])
            
            with col4:
                st.metric("‚úÖ Normales", 
                        st.session_state.unsupervised_metrics['puntos_normales'])
            
            # Visualizaci√≥n
            st.markdown("### üìà Visualizaci√≥n de Anomal√≠as")
            
            # Usar datos del modelo no supervisado entrenado
            if (hasattr(st.session_state, 'unsupervised_df') and 
                hasattr(st.session_state, 'unsupervised_feature_names') and
                len(st.session_state.unsupervised_feature_names) >= 2):
                
                unsupervised_df = st.session_state.unsupervised_df
                unsupervised_features = st.session_state.unsupervised_feature_names
                
                # Usar las dos primeras caracter√≠sticas para visualizaci√≥n
                fig = px.scatter(
                    x=unsupervised_df[unsupervised_features[0]], 
                    y=unsupervised_df[unsupervised_features[1]],
                    color=st.session_state.anomaly_labels,
                    color_discrete_map={1: 'blue', -1: 'red'},
                    labels={
                        'x': unsupervised_features[0],
                        'y': unsupervised_features[1],
                        'color': 'Tipo'
                    },
                    title="Detecci√≥n de Anomal√≠as (Rojo = Anomal√≠a, Azul = Normal)"
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # Gr√°fico de scores de anomal√≠a
                fig2 = px.histogram(
                    x=st.session_state.anomaly_scores,
                    nbins=30,
                    title="Distribuci√≥n de Scores de Anomal√≠a",
                    labels={'x': 'Score de Anomal√≠a', 'y': 'Frecuencia'}
                )
                st.plotly_chart(fig2, use_container_width=True)
        else:
            st.warning("‚ö†Ô∏è Has cambiado de dataset. Por favor, entrena nuevamente el modelo no supervisado para ver los resultados.")# ZONA DE EXPORTACI√ìN
elif mode == "üìÅ Zona de Exportaci√≥n":
    st.markdown("## üìÅ Zona de Exportaci√≥n (Dev Tools)")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### üìä Exportaci√≥n Modelo Supervisado")
        
        if st.session_state.supervised_model is not None:
            # JSON para modelo supervisado
            supervised_json = {
                "tipo_modelo": "Supervisado",
                "nombre_modelo": "Clasificador Gradient Boosting",
                "dataset_utilizado": st.session_state.dataset_name if st.session_state.dataset_name else "Desconocido",
                "fecha_hora": datetime.now().isoformat(),
                "metricas": st.session_state.supervised_metrics,
                "parametros": {
                    "num_estimadores": st.session_state.supervised_model.n_estimators,
                    "profundidad_maxima": st.session_state.supervised_model.max_depth,
                    "tasa_aprendizaje": st.session_state.supervised_model.learning_rate
                }
            }
            
            # Agregar √∫ltima predicci√≥n si existe
            if hasattr(st.session_state, 'last_prediction'):
                supervised_json["prediccion_actual"] = st.session_state.last_prediction
            
            # Convertir tipos numpy
            supervised_json = convert_numpy_types(supervised_json)
            
            # Bot√≥n de descarga JSON
            json_str = json.dumps(supervised_json, indent=2)
            st.download_button(
                label="üì• Descargar JSON Supervisado",
                data=json_str,
                file_name="resultados_modelo_supervisado.json",
                mime="application/json"
            )
            
            # Bot√≥n de descarga PKL
            model_pkl = pickle.dumps(st.session_state.supervised_model)
            st.download_button(
                label="üì• Descargar Modelo PKL",
                data=model_pkl,
                file_name="modelo_gradient_boosting.pkl",
                mime="application/octet-stream"
            )
            
            # Mostrar preview del JSON
            st.markdown("#### üëÄ Preview JSON:")
            st.json(supervised_json)
            
        else:
            st.warning("‚ö†Ô∏è No hay modelo supervisado entrenado.")
    
    with col2:
        st.markdown("### üîç Exportaci√≥n Modelo No Supervisado")
        
        if st.session_state.unsupervised_model is not None:
            # JSON para modelo no supervisado
            unsupervised_json = {
                "tipo_modelo": "No Supervisado",
                "algoritmo": "Bosque de Aislamiento",
                "dataset_utilizado": st.session_state.dataset_name if st.session_state.dataset_name else "Desconocido",
                "fecha_hora": datetime.now().isoformat(),
                "parametros": {
                    "contaminacion": st.session_state.unsupervised_model.contamination,
                    "num_estimadores": st.session_state.unsupervised_model.n_estimators,
                    "max_muestras": st.session_state.unsupervised_model.max_samples
                },
                "metricas": st.session_state.unsupervised_metrics,
                "etiquetas_cluster": st.session_state.cluster_labels.tolist() if hasattr(st.session_state, 'cluster_labels') else []
            }
            
            # Convertir tipos numpy
            unsupervised_json = convert_numpy_types(unsupervised_json)
            
            # Bot√≥n de descarga JSON
            json_str = json.dumps(unsupervised_json, indent=2)
            st.download_button(
                label="üì• Descargar JSON No Supervisado",
                data=json_str,
                file_name="resultados_modelo_no_supervisado.json",
                mime="application/json"
            )
            
            # Bot√≥n de descarga PKL
            model_pkl = pickle.dumps(st.session_state.unsupervised_model)
            st.download_button(
                label="üì• Descargar Isolation Forest PKL",
                data=model_pkl,
                file_name="modelo_bosque_aislamiento.pkl",
                mime="application/octet-stream"
            )
            
            # Mostrar preview del JSON
            st.markdown("#### üëÄ Preview JSON:")
            st.json(unsupervised_json)
            
        else:
            st.warning("‚ö†Ô∏è No hay modelo no supervisado entrenado.")

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
    Aplicaci√≥n de Machine Learning | Desarrollado con Streamlit | 2025
</div>
""", unsafe_allow_html=True)